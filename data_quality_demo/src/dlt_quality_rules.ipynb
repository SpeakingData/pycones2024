{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of how to get rules dynamically for DLT (not used in the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE OR REPLACE TABLE\n",
    "  data_quality_dlt_dev.rules\n",
    "AS SELECT\n",
    "  col1 AS name,\n",
    "  col2 AS constraint,\n",
    "  col3 AS tag\n",
    "FROM (\n",
    "  VALUES\n",
    "  (\"client_id_not_null\",\"client_id IS NOT NULL\",\"clients\"),\n",
    "  (\"address_valid_value\",\"address in ('New York', 'California', 'Texas', 'Florida', 'Illinois')\",\"clients\"),\n",
    "  (\"product_id_not_null\",\"product_id IS NOT NULL\",\"products\"),\n",
    "  (\"sales_id_not_null\",\"sales_id IS NOT NULL\",\"sales\"),\n",
    "  (\"client_id_not_null\",\"client_id IS NOT NULL\",\"sales\"),\n",
    "  (\"client_id_not_null\",\"client_id IS NOT NULL\",\"sales\"),\n",
    "  (\"date_valid_range\",\"date between '2020-01-01' and '2025-01-01'\",\"sales\"),\n",
    "  (\"quantity_valid_value\",\"quantity > 0\",\"sales\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "def get_rules(tag):\n",
    "  \"\"\"\n",
    "    loads data quality rules from a table\n",
    "    :param tag: tag to match\n",
    "    :return: dictionary of rules that matched the tag\n",
    "  \"\"\"\n",
    "  rules = {}\n",
    "  df = spark.read.table(\"data_quality_dlt_dev.rules\")\n",
    "  for row in df.filter(col(\"tag\") == tag).collect():\n",
    "    rules[row['name']] = row['constraint']\n",
    "  return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dlt.expect_all_or_drop(get_rules(table_name))\n",
    "def temp_silver():\n",
    "    return (\n",
    "        dlt.readStream(\"bronze_data_quality\")\n",
    "        .withColumn(\"process_timestamp\", F.current_timestamp())\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "dlt_pipeline",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
